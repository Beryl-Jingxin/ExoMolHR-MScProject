{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: HITRAN Online Information\n",
    "\n",
    "Get the names of molecules, iso-slugs and isotopoluge datasets from the api__urls.txt which saved the URLs with molecule, iso-slug and isotopologue. Combine them with '/' for reading files from folders more convenient later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule: ['AlH', 'C2H2', 'C2', 'CO2', 'H2O', 'H3O_p', 'NH3', 'TiO']\n",
      "Iso-slug: ['27Al-1H', '12C2-1H2', '12C2', '12C-16O2', '1H2-16O', '1H3-16O_p', '14N-1H3', '46Ti-16O', '47Ti-16O', '48Ti-16O', '49Ti-16O', '50Ti-16O']\n",
      "Isotopologue: ['AlHambra', 'aCeTY', '8states', 'UCL-4000', 'POKAZATEL', 'eXeL', 'CoYuTe', 'Toto']\n",
      "Total: ['AlH/27Al-1H/AlHambra', 'C2H2/12C2-1H2/aCeTY', 'C2/12C2/8states', 'CO2/12C-16O2/UCL-4000', 'H2O/1H2-16O/POKAZATEL', 'H3O_p/1H3-16O_p/eXeL', 'NH3/14N-1H3/CoYuTe', 'TiO/46Ti-16O/Toto', 'TiO/47Ti-16O/Toto', 'TiO/48Ti-16O/Toto', 'TiO/49Ti-16O/Toto', 'TiO/50Ti-16O/Toto']\n"
     ]
    }
   ],
   "source": [
    "molecule = []\n",
    "iso_slug = []\n",
    "isotopologue = []\n",
    "path_mol_iso = []\n",
    "for line in open('./data/url/api__urls.txt'):\n",
    "    molecule.append(line.split('/')[-4])\n",
    "    iso_slug.append(line.split('/')[-3])\n",
    "    isotopologue.append(line.split('/')[-2])\n",
    "    path_mol_iso.append(line.split('/')[-4] + '/' + line.split('/')[-3]\n",
    "                        + '/' + line.split('/')[-2])\n",
    "\n",
    "molecule_list = list(set(molecule))\n",
    "molecule_list.sort(key=molecule.index)\n",
    "\n",
    "iso_slug_list = list(set(iso_slug))\n",
    "iso_slug_list.sort(key=iso_slug.index)\n",
    "\n",
    "isotopologue_list = list(set(isotopologue))\n",
    "isotopologue_list.sort(key=isotopologue.index)\n",
    "\n",
    "path_mol_iso_list = list(set(path_mol_iso))\n",
    "path_mol_iso_list.sort(key=path_mol_iso.index)\n",
    "\n",
    "print('Molecule:', molecule_list)\n",
    "print('Iso-slug:', iso_slug_list)\n",
    "print('Isotopologue:', isotopologue_list)\n",
    "print('Total:', path_mol_iso_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the iso-slug names into the ones which are shown in the table of HITRAN online website. It will help us to get their corresponding molecule numbers, isotopologue numbers and fractional abundances. \n",
    "\n",
    "The HITRAN online URL is: https://hitran.org/docs/iso-meta/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exomol formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27AlH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12C2H2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12C16O2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>H216O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>H316O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>14NH3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>46Ti16O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>47Ti16O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>48Ti16O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>49Ti16O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>50Ti16O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exomol formula\n",
       "0           27AlH\n",
       "1          12C2H2\n",
       "2            12C2\n",
       "3         12C16O2\n",
       "4           H216O\n",
       "5          H316O+\n",
       "6           14NH3\n",
       "7         46Ti16O\n",
       "8         47Ti16O\n",
       "9         48Ti16O\n",
       "10        49Ti16O\n",
       "11        50Ti16O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unc_formula = pd.DataFrame(eval(str(iso_slug_list).replace('1H','H')\n",
    "                                .replace('-','').replace('_p','+')))\n",
    "unc_formula.columns = ['exomol formula']\n",
    "unc_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CO_2$ information for HITRAN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mol_iso_list = ['CO2/12C-16O2/UCL-4000']\n",
    "hitran_online = pd.DataFrame()\n",
    "hitran_online['molecule ID'] = ['2']\n",
    "hitran_online['isotopologue ID'] = ['1']\n",
    "hitran_online['exomol formula'] = ['12C16O2']\n",
    "hitran_online['fractional abundance'] = ['0.984204']\n",
    "hitran_online['Q(296K)'] = ['286.09']\n",
    "#hitran_online\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mol_iso = path_mol_iso_list[0]\n",
    "M_mol_iso = 'M of ' + path_mol_iso.replace('/','__')\n",
    "molecule_id = int(hitran_online['molecule ID'][0])\n",
    "isotopologue_id = int(hitran_online['isotopologue ID'][0])\n",
    "fractional_abundance = float(hitran_online['fractional abundance'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = './data/www.exomol.com/db/'\n",
    "\n",
    "# Create a folder for saving result files.\n",
    "# If the folder exists, save files directory,otherwise, create it.\n",
    "result_path = './data/result/csv/'\n",
    "# Determine whether the folder exists or not.\n",
    "if os.path.exists(result_path):\n",
    "    pass\n",
    "else:\n",
    "    # Create the folder.\n",
    "    os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Process Data\n",
    "\n",
    "## 2.1 Read States File\n",
    "\n",
    "Consider column names of states file with def files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gamma',\n",
       " 'e/f',\n",
       " 'n1',\n",
       " 'n2',\n",
       " 'l2',\n",
       " 'n3',\n",
       " 'm1',\n",
       " 'm2',\n",
       " 'm3',\n",
       " 'm4',\n",
       " 'm5',\n",
       " 'v1',\n",
       " 'v2',\n",
       " 'v3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mol_iso = path_mol_iso_list[0]\n",
    "def_path = glob.glob('./data/def/' + '*' + path_mol_iso.split('/')[1]\n",
    "                     + '__' + path_mol_iso.split('/')[2] + '.def')\n",
    "def_reader = pd.read_csv(def_path[0], sep='\\\\s+', names=['1','2','3','4','5'], header=None)\n",
    "list(def_reader[def_reader['4'].isin(['label'])]['1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_col_name = (['ID','energy','g_tot','J_tot','Unc']\n",
    "                   + ['Gtot','e/f','n1','n2','l2','n3','W',\n",
    "                      'm1','m2','l','m3','r','v1','v2','v3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read compressed states file in chunks directly. Extract rows of states file whose uncertainty indices are small than 0.001 to be the considered states file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>energy</th>\n",
       "      <th>g_tot</th>\n",
       "      <th>J_tot</th>\n",
       "      <th>Unc</th>\n",
       "      <th>Gtot</th>\n",
       "      <th>e/f</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>l2</th>\n",
       "      <th>n3</th>\n",
       "      <th>W</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>l</th>\n",
       "      <th>m3</th>\n",
       "      <th>r</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1285.408200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1388.184200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2548.366700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2671.142957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3544166</td>\n",
       "      <td>3544167</td>\n",
       "      <td>18992.838652</td>\n",
       "      <td>445</td>\n",
       "      <td>222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3548854</td>\n",
       "      <td>3548855</td>\n",
       "      <td>19329.864656</td>\n",
       "      <td>449</td>\n",
       "      <td>224</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3553211</td>\n",
       "      <td>3553212</td>\n",
       "      <td>19669.693358</td>\n",
       "      <td>453</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3557260</td>\n",
       "      <td>3557261</td>\n",
       "      <td>20012.319104</td>\n",
       "      <td>457</td>\n",
       "      <td>228</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3561008</td>\n",
       "      <td>3561009</td>\n",
       "      <td>20357.736192</td>\n",
       "      <td>461</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18719 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID        energy  g_tot  J_tot     Unc Gtot e/f  n1  n2  l2  n3  \\\n",
       "0              1      0.000000      1      0  0.0005   A1   e   0   0   0   0   \n",
       "1              2   1285.408200      1      0  0.0005   A1   e   0   2   0   0   \n",
       "2              3   1388.184200      1      0  0.0050   A1   e   1   0   0   0   \n",
       "3              4   2548.366700      1      0  0.0005   A1   e   1   2   0   0   \n",
       "4              5   2671.142957      1      0  0.0050   A1   e   2   0   0   0   \n",
       "...          ...           ...    ...    ...     ...  ...  ..  ..  ..  ..  ..   \n",
       "3544166  3544167  18992.838652    445    222  0.0000   A1   e   0   0   0   0   \n",
       "3548854  3548855  19329.864656    449    224  0.0000   A1   e   0   0   0   0   \n",
       "3553211  3553212  19669.693358    453    226  0.0000   A1   e   0   0   0   0   \n",
       "3557260  3557261  20012.319104    457    228  0.0000   A1   e   0   0   0   0   \n",
       "3561008  3561009  20357.736192    461    230  0.0000   A1   e   0   0   0   0   \n",
       "\n",
       "            W  m1  m2  l  m3  r  v1  v2  v3  \n",
       "0        1.00   0   0  0   0  1   0   0   0  \n",
       "1        1.00   1   0  0   0  2   0   0   1  \n",
       "2        1.00   1   0  0   0  1   1   0   0  \n",
       "3        1.00   2   0  0   0  3   1   0   1  \n",
       "4        1.00   2   0  0   0  2   1   1   0  \n",
       "...       ...  ..  .. ..  .. ..  ..  ..  ..  \n",
       "3544166  0.86  -1  -1 -1  -1 -1   0   0   0  \n",
       "3548854  0.86  -1  -1 -1  -1 -1   0   0   0  \n",
       "3553211  0.85  -1  -1 -1  -1 -1   0   0   0  \n",
       "3557260  0.85  -1  -1 -1  -1 -1   0   0   0  \n",
       "3561008  0.85  -1  -1 -1  -1 -1   0   0   0  \n",
       "\n",
       "[18719 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df = dict()\n",
    "states_df = pd.DataFrame()\n",
    "states_filenames = glob.glob(read_path + path_mol_iso + '/' + path_mol_iso.split('/')[1]\n",
    "                             + '__' + path_mol_iso.split('/')[2] + '.states.bz2')\n",
    "\n",
    "for states_filename in states_filenames:\n",
    "    s_df[states_filename] = pd.read_csv(states_filename, compression='bz2', sep='\\s+',\n",
    "                                        header=None, names=states_col_name,\n",
    "                                        chunksize=100_000_000, iterator=True,\n",
    "                                        low_memory=False)\n",
    "    for chunk in s_df[states_filename]:\n",
    "        states_df = states_df.append(chunk)\n",
    "        \n",
    "# Extract rows of states file whose uncertainty indices are small than 0.01.\n",
    "unc_states_df = states_df[states_df['Unc'] < float(0.01)]\n",
    "unc_states_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Read Partition Function File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.0983"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_col_name = ['T', 'Q']\n",
    "pf_path = read_path + path_mol_iso + '/' + path_mol_iso.replace('/','__') + '_pf.csv'\n",
    "\n",
    "pf_url = ('http://www.exomol.com/db/' + path_mol_iso + '/'\n",
    "          + path_mol_iso.split('/')[1] + '__' + path_mol_iso.split('/')[2] + '.pf')   \n",
    "response = requests.get(pf_url)\n",
    "content = response.text  \n",
    "pf_data = pd.read_csv(StringIO(content), sep='\\s+', names=pf_col_name, header=None, engine='python')\n",
    "pf_data.to_csv(pf_path, header=False)\n",
    "\n",
    "pf_df = pd.read_csv(pf_path, header=None, names=pf_col_name)\n",
    "# Partition function defined as sum over states at standard 296K\n",
    "Q = pf_df.iloc[296-1]['Q']\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Read Transitions Files\n",
    "\n",
    "Extract rows of transitionos files whose upper states ID and lower states ID are all in considered states file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unc_trans(trans_df):\n",
    "    upper_id = trans_df['i'].values\n",
    "    lower_id = trans_df['f'].values\n",
    "    state_id = unc_states_df['ID'].values\n",
    "    \n",
    "    # Extract the same upper states ID from states_df\n",
    "    unc_trans_i_df = pd.DataFrame()\n",
    "    for id_1 in tqdm(state_id):\n",
    "        unc_trans_i_df = unc_trans_i_df.append(trans_df[trans_df['i'].isin([id_1])])\n",
    "        \n",
    "    # Extract the same lower states ID from states_df\n",
    "    unc_trans_df = pd.DataFrame()\n",
    "    for id_2 in tqdm(state_id):\n",
    "        unc_trans_df = unc_trans_df.append(unc_trans_i_df[unc_trans_i_df['f'].isin([id_2])])\n",
    "        \n",
    "    return unc_trans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Calculating\n",
    "\n",
    "HITRAN Parameters for calculating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 296                      # Reference temperature k\n",
    "h = 6.62607015e-34           # Planck's const (J s)\n",
    "c = 299792458                # Velocity of light (m s-1)\n",
    "kB = 1.380649e-23            # Boltzmann's const (J K-1)\n",
    "\n",
    "c2 = h * c * 100 / kB                  # Second radiation constant (cm K)\n",
    "pi_c_8 = 1 / (8 * np.pi * c * 100)     # 8 * pi * c (cm-1 s)\n",
    "c2_T = c2 / T                          # c2 / T  (cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data for CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_csv(unc_states_df, unc_trans_df):\n",
    "    unc_upper_id = unc_trans_df['i'].values\n",
    "    unc_lower_id = unc_trans_df['f'].values \n",
    "    state_id = unc_states_df['ID']\n",
    "    unc_trans_num = unc_trans_df['i'].count()\n",
    "\n",
    "    wavenumber = []                         # Vacuum wavenumber (cm−1)\n",
    "    intensity = pd.DataFrame()              # Intensities (cm-1/molecule cm-2) at standard 296K         \n",
    "    A_coefficient = []                      # Einstein A-coefficient\n",
    "    lower_state_energy = pd.DataFrame()     # lower state energy\n",
    "    uncertainty = []                        # Uncertainty indices\n",
    "    weight_upper_state = pd.DataFrame()     # Statistical weight of upper state\n",
    "    weight_lower_state = pd.DataFrame()     # Statistical weight of lower state\n",
    "    upper_global_quanta = []                # Upper-state 'global' quanta\n",
    "    lower_global_quanta = []                # Lower-state 'global' quanta\n",
    "    upper_local_quanta = []                 # Upper-state 'local' quanta\n",
    "    lower_local_quanta = []                 # Lower-state 'local' quanta\n",
    "\n",
    "    for i in tqdm(range(unc_trans_num)):\n",
    "        id_i = unc_upper_id[i]\n",
    "        id_f = unc_lower_id[i]\n",
    "        A = unc_trans_df['A_if'].values[i]                               # Einstein-A coefficient (s−1)\n",
    "        g_i = unc_states_df[state_id.isin([id_i])]['g_tot'].values       # Total degeneracy of upper state\n",
    "        g_f = unc_states_df[state_id.isin([id_f])]['g_tot'].values       # Total degeneracy of lower state\n",
    "        E_i = unc_states_df[state_id.isin([id_i])]['energy'].values      # Upper state energy\n",
    "        E_f = unc_states_df[state_id.isin([id_f])]['energy'].values      # Lower state energy\n",
    "        unc_i = unc_states_df[state_id.isin([id_i])]['Unc'].values       # Uncertainty indices of upper state\n",
    "        unc_f = unc_states_df[state_id.isin([id_f])]['Unc'].values       # Uncertainty indices of lower state\n",
    "        \n",
    "        u_m1 = unc_states_df[state_id.isin([id_i])]['m1'].values[0]\n",
    "        u_m2 = unc_states_df[state_id.isin([id_i])]['m2'].values[0]\n",
    "        u_m3 = unc_states_df[state_id.isin([id_i])]['m3'].values[0]\n",
    "        u_l = unc_states_df[state_id.isin([id_i])]['l'].values[0]\n",
    "        u_r = unc_states_df[state_id.isin([id_i])]['r'].values[0]\n",
    "        u_J = unc_states_df[state_id.isin([id_i])]['J_tot'].values[0]\n",
    "        u_ef = unc_states_df[state_id.isin([id_i])]['e/f'].values[0]\n",
    "\n",
    "        l_m1 = unc_states_df[state_id.isin([id_f])]['m1'].values[0]\n",
    "        l_m2 = unc_states_df[state_id.isin([id_f])]['m2'].values[0]\n",
    "        l_m3 = unc_states_df[state_id.isin([id_f])]['m3'].values[0]\n",
    "        l_l = unc_states_df[state_id.isin([id_f])]['l'].values[0]\n",
    "        l_r = unc_states_df[state_id.isin([id_f])]['r'].values[0]\n",
    "        l_J = unc_states_df[state_id.isin([id_f])]['J_tot'].values[0]\n",
    "        l_ef = unc_states_df[state_id.isin([id_f])]['e/f'].values[0]\n",
    "\n",
    "        V_i = '     %2d%2d%2d%2d%2d' % (u_m1,u_m2,u_l,u_m3,u_r) + ','      # Upper-state 'global' quanta\n",
    "        V_f = '     %2d%2d%2d%2d%2d' % (l_m1,l_m2,l_l,l_m3,l_r) + ','      # Lower-state 'global' quanta\n",
    "        Q_i = '          %3d%2s' % (u_J,u_ef) + ','                        # Upper-state 'local' quanta\n",
    "        Q_f = '          %3d%2s' % (l_J,l_ef) + ','                        # Lower-state 'local' quanta\n",
    "\n",
    "        unc = math.sqrt(unc_i ** 2 + unc_f ** 2)                           # Uncertainty idices\n",
    "        v = float(abs(E_i - E_f))                                          # Vacuum wavenumber (cm−1)\n",
    "        S = g_i * A * np.exp(- c2_T * E_f) * (1 - np.exp(- c2_T * v)) * pi_c_8 / (v ** 2) / Q    # Intensities\n",
    "\n",
    "        wavenumber.append(v)\n",
    "        intensity = intensity.append(pd.DataFrame(S))\n",
    "        A_coefficient.append(A)\n",
    "        lower_state_energy = lower_state_energy.append(pd.DataFrame(E_f))\n",
    "        uncertainty.append(unc)\n",
    "        weight_upper_state = weight_upper_state.append(pd.DataFrame(g_i))\n",
    "        weight_lower_state = weight_lower_state.append(pd.DataFrame(g_f))\n",
    "        upper_global_quanta += V_i.split(',')\n",
    "        lower_global_quanta += V_f.split(',')\n",
    "        upper_local_quanta += Q_i.split(',')\n",
    "        lower_local_quanta += Q_f.split(',')\n",
    "    \n",
    "    iso_csv_df = pd.DataFrame()\n",
    "    iso_csv_df['v'] = wavenumber                       # Vacuum wavenumber (cm−1)\n",
    "    iso_csv_df['S'] = intensity.values                 # Intensities (cm-1/molecule cm-2) at standard 296K  \n",
    "    iso_csv_df['A'] = A_coefficient                    # Einstein A-coefficient\n",
    "    iso_csv_df['E_f'] = lower_state_energy.values      # Lower state energy\n",
    "    iso_csv_df['Ierr'] = uncertainty                   # Uncertainty indices\n",
    "    iso_csv_df['g_i'] = weight_upper_state.values      # Statistical weight of upper state\n",
    "    iso_csv_df['g_f'] = weight_lower_state.values      # Statistical weight of lower state\n",
    "    iso_csv_df[M_mol_iso] = molecule_id                # Molecule number\n",
    "    iso_csv_df['I'] = isotopologue_id                  # Isotopologue number\n",
    "    iso_csv_df['gm_a'] = np.nan                        # Air-broadened half-width\n",
    "    iso_csv_df['gm_s'] = np.nan                        # Self-broadened half-width\n",
    "    iso_csv_df['n_a'] = np.nan                         # Temperature-dependence exponent for gamma_air\n",
    "    iso_csv_df['dt_a'] = np.nan                        # Air pressure-induced line shift\n",
    "    iso_csv_df['V_i'] = list(filter(None, upper_global_quanta))            # Upper-state 'global' quanta\n",
    "    iso_csv_df['V_f'] = list(filter(None, lower_global_quanta))            # Lower-state 'global' quanta\n",
    "    iso_csv_df['Q_i'] = list(filter(None, upper_local_quanta))             # Upper-state 'local' quanta\n",
    "    iso_csv_df['Q_f'] = list(filter(None, lower_local_quanta))             # Lower-state 'local' quanta                  \n",
    "    iso_csv_df['Iref'] = np.nan                        # Reference indices\n",
    "    iso_csv_df['*'] = np.nan                           # Flag\n",
    "\n",
    "    return iso_csv_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Save as CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_col_name = ['i', 'f', 'A_if']\n",
    "t_df = dict()\n",
    "species_csv_df = pd.DataFrame()\n",
    "trans_filenames = glob.glob(read_path + path_mol_iso + '/' + '*trans.bz2')\n",
    "for trans_filename in tqdm(trans_filenames):\n",
    "    t_df[trans_filename] = pd.read_csv(trans_filename, compression='bz2', sep='\\s+',\n",
    "                                       usecols=[0,1,2], header=None, names=trans_col_name,\n",
    "                                       chunksize=100_000_000, iterator=True, low_memory=False)\n",
    "    # Set an empty DataFrame to avoid meeting empty considered transitions files.\n",
    "    iso_csv_df = pd.DataFrame()\n",
    "    for trans_df in t_df[trans_filename]:\n",
    "        unc_trans_df = extract_unc_trans(trans_df)\n",
    "        if len(unc_trans_df) != 0:\n",
    "            iso_csv_df = calculate_csv(unc_states_df, unc_trans_df)\n",
    "            \n",
    "    species_csv_df = species_csv_df.append(iso_csv_df)\n",
    "\n",
    "order = [M_mol_iso, 'I', 'v', 'S', 'A', 'gm_a', 'gm_s', 'E_f', 'n_a', 'dt_a',\n",
    "         'V_i', 'V_f', 'Q_i', 'Q_f', 'Ierr', 'Iref', '*', 'g_i', 'g_f']\n",
    "species_csv_df = species_csv_df[order]\n",
    "# Sort by increasing wavenumber\n",
    "species_csv_df = species_csv_df.sort_values(['v'], ascending = True).reset_index(drop=True)\n",
    "# Save into a CSV file with column names which contain molecule name.\n",
    "species_csv_df.to_csv(result_path + path_mol_iso.replace('/','__') + '.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
