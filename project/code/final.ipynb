{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from io import StringIO\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule: ['AlH', 'C2H2', 'C2', 'CO2', 'H2O', 'H3O_p', 'NH3', 'TiO']\n",
      "Iso-slug: ['27Al-1H', '12C2-1H2', '12C2', '12C-16O2', '1H2-16O', '1H3-16O_p', '14N-1H3', '46Ti-16O', '47Ti-16O', '48Ti-16O', '49Ti-16O', '50Ti-16O']\n",
      "Isotopologue: ['AlHambra', 'aCeTY', '8states', 'UCL-4000', 'POKAZATEL', 'eXeL', 'CoYuTe', 'Toto']\n",
      "Total: ['AlH/27Al-1H/AlHambra', 'C2H2/12C2-1H2/aCeTY', 'C2/12C2/8states', 'CO2/12C-16O2/UCL-4000', 'H2O/1H2-16O/POKAZATEL', 'H3O_p/1H3-16O_p/eXeL', 'NH3/14N-1H3/CoYuTe', 'TiO/46Ti-16O/Toto', 'TiO/47Ti-16O/Toto', 'TiO/48Ti-16O/Toto', 'TiO/49Ti-16O/Toto', 'TiO/50Ti-16O/Toto']\n"
     ]
    }
   ],
   "source": [
    "molecule = []\n",
    "iso_slug = []\n",
    "isotopologue = []\n",
    "path_mol_iso = []\n",
    "for line in open('./data/url/api__urls.txt'):\n",
    "    molecule.append(line.split('/')[-4])\n",
    "    iso_slug.append(line.split('/')[-3])\n",
    "    isotopologue.append(line.split('/')[-2])\n",
    "    path_mol_iso.append(line.split('/')[-4] + '/' + line.split('/')[-3] + '/' + line.split('/')[-2])\n",
    "\n",
    "molecule_list = list(set(molecule))\n",
    "molecule_list.sort(key=molecule.index)\n",
    "\n",
    "iso_slug_list = list(set(iso_slug))\n",
    "iso_slug_list.sort(key=iso_slug.index)\n",
    "\n",
    "isotopologue_list = list(set(isotopologue))\n",
    "isotopologue_list.sort(key=isotopologue.index)\n",
    "\n",
    "path_mol_iso_list = list(set(path_mol_iso))\n",
    "path_mol_iso_list.sort(key=path_mol_iso.index)\n",
    "\n",
    "print('Molecule:', molecule_list)\n",
    "print('Iso-slug:', iso_slug_list)\n",
    "print('Isotopologue:', isotopologue_list)\n",
    "print('Total:', path_mol_iso_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molparam_url = 'https://hitran.org/docs/iso-meta/'\n",
    "hitran_reader = pd.read_html(molparam_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitran_reader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_formula = pd.DataFrame(eval(str(iso_slug_list).replace('1H','H').replace('-','').replace('_p','+')))\n",
    "unc_formula.columns = ['exomol formula']\n",
    "unc_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitran_online = pd.DataFrame()\n",
    "hitran_online['exomol formula'] = unc_formula['exomol formula']\n",
    "hitran_online['molecule id'] = pd.Series()\n",
    "hitran_online['isotopologue id'] = pd.Series()\n",
    "hitran_online['fractional abundance'] = pd.Series()\n",
    "hitran_num = hitran_online['exomol formula'].count()\n",
    "\n",
    "for k in range(hitran_num):\n",
    "    for i in range(len(hitran_reader)):\n",
    "        formula_n = hitran_reader[i]['Formula'].count()\n",
    "        for j in range(formula_n):\n",
    "            if (hitran_online['exomol formula'][k] == hitran_reader[i]['Formula'][j]):\n",
    "                hitran_online['molecule id'][k] = int(i + 1)\n",
    "                hitran_online['isotopologue id'][k] = int(j + 1)\n",
    "                hitran_online['fractional abundance'][k] = hitran_reader[i]['Abundance'][j]\n",
    "\n",
    "\n",
    "hitran_online['molecule id'] = [str(hitran_online['molecule id'][k]).replace('nan',str(49+k)) for k in range(hitran_num)]\n",
    "hitran_online['isotopologue id'] = [str(hitran_online['isotopologue id'][k]).replace('nan','1') for k in range(hitran_num)]\n",
    "hitran_online['fractional abundance'] = [str(hitran_online['fractional abundance'][k]).replace('nan','1') for k in range(hitran_num)]\n",
    "\n",
    "hitran_online\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the information is not complete and some of our considered molecules are not in the table of HITRAN online, we list them here for the following code. The information for those not included molecules are  hypothetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hitran_online = pd.DataFrame()\n",
    "hitran_online['exomol formula'] = unc_formula['exomol formula']\n",
    "hitran_online['molecule ID'] = ['50','26','51','2','1','52','11','53','53','53','53','53']\n",
    "hitran_online['isotopologue ID'] = ['1','1','1','1','1','1','1','1','2','3','4','5']\n",
    "hitran_online['fractional  abundance'] = ['1','0.977599','1','0.984204','0.997317','1','0.995872','0.2','0.2','0.2','0.2','0.2']\n",
    "#hitran_online\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hitran_num = len(hitran_reader)\n",
    "molecule_id = []\n",
    "isotopologue_id = []\n",
    "formulas = []\n",
    "fractional_abundance = []\n",
    "\n",
    "for formula in hitran_formula[0]:\n",
    "    for i in range(hitran_num):\n",
    "        formula_n = hitran_reader[i]['Formula'].count()\n",
    "        for j in range(formula_n):\n",
    "            if (formula == hitran_reader[i]['Formula'][j]):\n",
    "                id_i = i\n",
    "                id_j = j\n",
    "                molecule_id.append(int(id_i + 1))\n",
    "                isotopologue_id.append(int(id_j + 1))\n",
    "                formulas.append(hitran_reader[i]['Formula'][j])\n",
    "                fractional_abundance.append(hitran_reader[i]['Abundance'][j])\n",
    "\n",
    "hitran_online = pd.DataFrame()\n",
    "hitran_online['molecule ID'] = molecule_id\n",
    "hitran_online['isotopologue ID'] = isotopologue_id\n",
    "hitran_online['exomol formula'] = formulas\n",
    "hitran_online['fractional abundance'] = fractional_abundance\n",
    "hitran_online\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitran_online = pd.DataFrame()\n",
    "hitran_online['molecule ID'] = ['11']\n",
    "hitran_online['isotopologue ID'] = ['1']\n",
    "hitran_online['exomol formula'] = ['14NH3']\n",
    "hitran_online['fractional abundance'] = ['0.995872']\n",
    "hitran_online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_mol_iso_list = ['AlH/27Al-1H/AlHambra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mol_iso_list = ['NH3/14N-1H3/CoYuTe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 296                      # Reference temperature k\n",
    "h = 6.62607015e-34           # Planck's const (J s)\n",
    "c = 299792458                # Velocity of light (m s-1)\n",
    "kB = 1.380649e-23            # Boltzmann's const (J K-1)\n",
    "\n",
    "c2 = h * c * 100 / kB                  # Second radiation constant (cm K)\n",
    "pi_c_8 = 1 / (8 * np.pi * c * 100)     # 8 * pi * c (cm-1 s)\n",
    "c2_T = c2 / T                          # c2 / T  (cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unc_trans(trans_df):\n",
    "    upper_id = trans_df['i'].values\n",
    "    lower_id = trans_df['f'].values\n",
    "    state_id = unc_states_df['N'].values\n",
    "    \n",
    "    # Extract the same upper states ID from states_df\n",
    "    unc_trans_i_df = pd.DataFrame()\n",
    "    for id_1 in tqdm(state_id):\n",
    "        unc_trans_i_df = unc_trans_i_df.append(trans_df[trans_df['i'].isin([id_1])])\n",
    "        \n",
    "    # Extract the same lower states ID from states_df\n",
    "    unc_trans_df = pd.DataFrame()\n",
    "    for id_2 in tqdm(state_id):\n",
    "        unc_trans_df = unc_trans_df.append(unc_trans_i_df[unc_trans_i_df['f'].isin([id_2])])\n",
    "        \n",
    "    return unc_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_csv(unc_states_df, unc_trans_df):\n",
    "    \n",
    "\n",
    "    unc_upper_id = unc_trans_df['i'].values\n",
    "    unc_lower_id = unc_trans_df['f'].values \n",
    "    state_id = unc_states_df['N']\n",
    "    unc_trans_num = unc_trans_df['i'].count()\n",
    "\n",
    "    wavenumber = []                         # Vacuum wavenumber (cm−1)\n",
    "    intensity = pd.DataFrame()              # Intensities (cm-1/molecule cm-2) at standard 296K         \n",
    "    A_coefficient = []                      # Einstein A-coefficient\n",
    "    lower_state_energy = pd.DataFrame()     # lower state energy\n",
    "    uncertainty = []                        # Uncertainty indices\n",
    "    weight_upper_state = pd.DataFrame()     # Nuclear-spin statistical weight of upper state\n",
    "    weight_lower_state = pd.DataFrame()     # Nuclear-spin statistical weight of lower state\n",
    "\n",
    "\n",
    "    for i in tqdm(range(unc_trans_num)):\n",
    "        id_i = unc_upper_id[i]\n",
    "        id_f = unc_lower_id[i]\n",
    "        A = unc_trans_df['A_if'].values[i]                               # Einstein-A coefficient (s−1)\n",
    "        J_i = unc_states_df[state_id.isin([id_i])]['J'].values           # Corresponding total angular momentum\n",
    "        g_i_ns = unc_states_df[state_id.isin([id_i])]['g'].values        # Nuclear-spin statistical weight of upper state\n",
    "        g_f_ns = unc_states_df[state_id.isin([id_f])]['g'].values        # Nuclear-spin statistical weight of lower state\n",
    "        E_i = unc_states_df[state_id.isin([id_i])]['E'].values           # Upper state energy\n",
    "        E_f = unc_states_df[state_id.isin([id_f])]['E'].values           # Lower state energy\n",
    "        unc_i = unc_states_df[state_id.isin([id_i])]['Unc'].values       # Uncertainty indices of upper state\n",
    "        unc_f = unc_states_df[state_id.isin([id_i])]['Unc'].values       # Uncertainty indices of lower state\n",
    "\n",
    "        g_i_tot = g_i_ns * (2 * J_i + 1)                                 # Total degeneracy\n",
    "        unc = math.sqrt(unc_i ** 2 + unc_f ** 2)                         # Uncertainty idices\n",
    "        v = float(E_i - E_f)                                             # Vacuum wavenumber (cm−1)\n",
    "        S = g_i_tot * A * np.exp(- c2_T * E_f) * (1 - np.exp(- c2_T * v)) * pi_c_8 / (v ** 2) / Q    # Intensities\n",
    "\n",
    "        wavenumber.append(v)\n",
    "        intensity = intensity.append(pd.DataFrame(S))\n",
    "        A_coefficient.append(A)\n",
    "        lower_state_energy = lower_state_energy.append(pd.DataFrame(E_f))\n",
    "        uncertainty.append(unc)\n",
    "        weight_upper_state = weight_upper_state.append(pd.DataFrame(g_i_ns))\n",
    "        weight_lower_state = weight_lower_state.append(pd.DataFrame(g_f_ns))\n",
    "    \n",
    "    iso_csv_df = pd.DataFrame()\n",
    "    iso_csv_df['v'] = wavenumber                       # Vacuum wavenumber (cm−1)\n",
    "    iso_csv_df['S'] = intensity.values                 # Intensities (cm-1/molecule cm-2) at standard 296K  \n",
    "    iso_csv_df['A'] = A_coefficient                    # Einstein A-coefficient\n",
    "    iso_csv_df['E_f'] = lower_state_energy.values      # Lower state energy\n",
    "    iso_csv_df['Ierr'] = uncertainty                   # Uncertainty indices\n",
    "    iso_csv_df['g_i'] = weight_upper_state.values      # Nuclear-spin statistical weight of upper state\n",
    "    iso_csv_df['g_f'] = weight_lower_state.values      # Nuclear-spin statistical weight of lower state\n",
    "    iso_csv_df[M_mol_iso] = molecule_id                # Molecule number\n",
    "    iso_csv_df['I'] = isotopologue_id                  # Isotopologue number\n",
    "    iso_csv_df['gm_a'] = np.nan                        # Air-broadened half-width\n",
    "    iso_csv_df['gm_s'] = np.nan                        # Self-broadened half-width\n",
    "    iso_csv_df['n_a'] = np.nan                         # Temperature-dependence exponent for gamma_air\n",
    "    iso_csv_df['dt_a'] = np.nan                        # Air pressure-induced line shift\n",
    "    iso_csv_df['V_i'] = np.nan                         # Upper-state 'global' quanta\n",
    "    iso_csv_df['V_f'] = np.nan                         # Lower-state 'global' quanta\n",
    "    iso_csv_df['Q_i'] = np.nan                         # Upper-state 'local' quanta\n",
    "    iso_csv_df['Q_f'] = np.nan                         # Lower-state 'local' quanta\n",
    "    iso_csv_df['Iref'] = np.nan                        # Reference indices\n",
    "    iso_csv_df['*'] = np.nan                           # Flag\n",
    "\n",
    "    return iso_csv_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uncertainty_code(HITRAN_df):\n",
    "    HITRAN_num = HITRAN_df['Ierr'].count()\n",
    "    Ierr = []\n",
    "    for i in range(HITRAN_num):\n",
    "        uncertainty = HITRAN_df['Ierr'].values[i]\n",
    "        uncertainty_value = float(uncertainty)\n",
    "        if (0.0001 <= uncertainty_value < 0.001):\n",
    "            uncertainty_code = '{:_>6}'.format(4)\n",
    "        elif (0.00001 <= uncertainty_value < 0.0001):\n",
    "            uncertainty_code = '{:_>6}'.format(5)\n",
    "        elif (0.000001 <= uncertainty_value < 0.00001):\n",
    "            uncertainty_code = '{:_>6}'.format(6)\n",
    "        elif (0.0000001 <= uncertainty_value < 0.000001):\n",
    "            uncertainty_code = '{:_>6}'.format(7)\n",
    "        elif (uncertainty_value < 0.0000001):\n",
    "            uncertainty_code = '{:_>6}'.format(8)\n",
    "        Ierr.append(uncertainty_code)\n",
    "    return Ierr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_HITRAN(csv_df):\n",
    "    HITRAN_df = csv_df[csv_df.S > 1.0E-30]\n",
    "    Ierr = convert_uncertainty_code(HITRAN_df)\n",
    "    \n",
    "    HITRAN_df['M'] = HITRAN_df.M.map('{:_>2}'.format)\n",
    "    HITRAN_df['I'] = HITRAN_df.I.map('{:>1}'.format)\n",
    "    HITRAN_df['v'] = HITRAN_df.v\n",
    "    HITRAN_df['S'] = HITRAN_df.S * fractional_abundance\n",
    "    HITRAN_df['S'] = HITRAN_df.S.map('{:_>10.3E}'.format)\n",
    "    HITRAN_df['A'] = HITRAN_df.A.map('{:_>10.3E}'.format)\n",
    "    HITRAN_df['gm_a'] = '_' * 5\n",
    "    HITRAN_df['gm_s'] = '_' * 5\n",
    "    HITRAN_df['E_f'] = HITRAN_df.E_f.map('{:_>10.4F}'.format)\n",
    "    HITRAN_df['n_a'] = '_' * 4\n",
    "    HITRAN_df['dt_a'] = '_' * 8\n",
    "    HITRAN_df['V_i'] = '_' * 15\n",
    "    HITRAN_df['V_f'] = '_' * 15\n",
    "    HITRAN_df['Q_i'] = '_' * 15\n",
    "    HITRAN_df['Q_f'] = '_' * 15\n",
    "    HITRAN_df['Ierr'] = Ierr\n",
    "    HITRAN_df['Iref'] = '_' * 12\n",
    "    HITRAN_df['*'] = '_'\n",
    "    HITRAN_df['g_i'] = HITRAN_df.g_i.map('{:_>7.1F}'.format)\n",
    "    HITRAN_df['g_f'] = HITRAN_df.g_f.map('{:_>7.1F}'.format)\n",
    "    \n",
    "    HITRAN_df = HITRAN_df.sort_values(['v'], ascending = True).reset_index(drop=True)\n",
    "    HITRAN_df['v'] = HITRAN_df['v'].map('{:_>12.6F}'.format)\n",
    "    return HITRAN_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = './data/www.exomol.com/db/'\n",
    "\n",
    "# Create a folder for saving result files.\n",
    "# If the folder exists, delete (empty) the folder then create it.\n",
    "result_path = './data/demo_result/'\n",
    "if os.path.exists(result_path):                    # Determine whether the folder exists or not.\n",
    "    for root, dirs, files in os.walk(result_path, topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))    # Delete files in the folder.\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))     # Delete the sub-folder.\n",
    "    os.rmdir(result_path)                          # Delete the folder.\n",
    "os.mkdir(result_path)                              # Create the folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_col_name = ['N','E','g','J','Unc']\n",
    "trans_col_name = ['i', 'f', 'A_if']\n",
    "pf_col_name = ['T', 'Q']\n",
    "\n",
    "mol_iso_num = len(path_mol_iso_list)\n",
    "for i in tqdm(range(mol_iso_num)):\n",
    "    path_mol_iso = path_mol_iso_list[i]\n",
    "    M_mol_iso = 'M of ' + path_mol_iso.replace('/','__')\n",
    "    molecule_id = int(hitran_online['molecule ID'][i])\n",
    "    isotopologue_id = int(hitran_online['isotopologue ID'][i])\n",
    "    fractional_abundance = float(hitran_online['fractional abundance'][i])\n",
    "\n",
    "    pf_url = ('http://www.exomol.com/db/' + path_mol_iso + '/'\n",
    "              + path_mol_iso.split('/')[1] + '__'\n",
    "              + path_mol_iso.split('/')[2] + '.pf')   \n",
    "    response = requests.get(pf_url)\n",
    "    content = response.text  \n",
    "    pf_data = pd.read_csv(StringIO(content), sep='\\s+', names=pf_col_name, header=None, engine='python')\n",
    "    pf_path = read_path + path_mol_iso + '/' + path_mol_iso.replace('/','__') + '_pf.csv'\n",
    "    pf_data.to_csv(pf_path, header=False)\n",
    "    pf_df = pd.read_csv(pf_path, usecols=[0,1], header=None, names=pf_col_name)\n",
    "    # Partition function defined as sum over states at standard 296K\n",
    "    Q = pf_df['Q'].values[296-1]\n",
    "        \n",
    "    s_df = dict()\n",
    "    states_df = pd.DataFrame()\n",
    "    states_filenames = glob.glob(read_path + path_mol_iso + '/' + '*states.bz2')\n",
    "\n",
    "    for states_filename in states_filenames:\n",
    "        s_df[states_filename] = pd.read_csv(states_filename, compression='bz2', sep='\\s+', usecols=[0,1,2,3,4], header=None,\n",
    "                                            names=states_col_name, chunksize=100_000_000,\n",
    "                                            iterator=True, low_memory=False)\n",
    "        for chunk in s_df[states_filename]:\n",
    "            states_df = states_df.append(chunk)\n",
    "\n",
    "    # Extract rows of states file whose uncertainty indices are small than 0.001.\n",
    "    unc_states_df = states_df[states_df['Unc'] < float(0.001)]\n",
    "    \n",
    "    t_df = dict()\n",
    "    species_csv_df = pd.DataFrame()\n",
    "    trans_filenames = glob.glob(read_path + path_mol_iso + '/' + '*trans.bz2')\n",
    "    for trans_filename in tqdm(trans_filenames):\n",
    "        t_df[trans_filename] = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', usecols=[0,1,2], header=None,\n",
    "                                           names=trans_col_name, chunksize=100_000_000,\n",
    "                                           iterator=True, low_memory=False)\n",
    "\n",
    "        for trans_df in t_df[trans_filename]:\n",
    "            unc_trans_df = extract_unc_trans(trans_df)\n",
    "            if len(unc_trans_df) != 0:\n",
    "                iso_csv_df = calculate_csv(unc_states_df, unc_trans_df)\n",
    "            \n",
    "        species_csv_df = species_csv_df.append(iso_csv_df)\n",
    "\n",
    "    order = [M_mol_iso, 'I', 'v', 'S', 'A', 'gm_a', 'gm_s', 'E_f', 'n_a', 'dt_a',\n",
    "                 'V_i', 'V_f', 'Q_i', 'Q_f', 'Ierr', 'Iref', '*', 'g_i', 'g_f']\n",
    "    species_csv_df = species_csv_df[order]\n",
    "    # Sort by increasing wavenumber\n",
    "    species_csv_df = species_csv_df.sort_values(['v'], ascending = True).reset_index(drop=True)\n",
    "\n",
    "    species_csv_df.to_csv(result_path + path_mol_iso.replace('/','__') + '.csv', header=True, index=False)   \n",
    "    species_csv_df.to_csv(result_path + 'csv_result.csv', header=True, index=False, mode='a')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_col_name = ['M', 'I', 'v', 'S', 'A', 'gamma_air', 'gamma_self',\n",
    "                   'E_f', 'n_air', 'delta_air', 'V_i', 'V_f', 'Q_i', 'Q_f',\n",
    "                   'Ierr', 'Iref', '*', 'g_i', 'g_f']\n",
    "\n",
    "csv_reader = pd.read_csv(result_path + 'csv_result.csv', names = result_col_name, header=None, chunksize=100_000_000, iterator=True, low_memory=False)\n",
    "for csv_df in csv_reader:\n",
    "    csv_df = csv_df[~csv_df['I'].isin(['I'])]\n",
    "    csv_df = csv_df.astype(float)\n",
    "    HITRAN_df = convert_csv_to_HITRAN(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HITRAN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HITRAN_df.to_csv(result_path + 'demo.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_in_chunks(path, chunk_size=1024*1024):\n",
    "    file = open(path, 'r')\n",
    "    while True:\n",
    "        chunk_data = file.read(chunk_size)\n",
    "        if not chunk_data:\n",
    "            break\n",
    "        yield chunk_data\n",
    "\n",
    "HITRAN_path = result_path + 'demo.txt'\n",
    "with open(result_path + 'HITRAN_result.txt', 'w') as save_file:\n",
    "    for chunk in read_txt_in_chunks(HITRAN_path):\n",
    "        string = str(chunk).replace(',','').replace('_',' ')\n",
    "        save_file.write(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(mol_iso_num)):\n",
    "    path_mol_iso = path_mol_iso_list[i]\n",
    "    def_path = glob.glob('./data/def/' + '*' + path_mol_iso.split('/')[1] + '__' + path_mol_iso.split('/')[2] + '.def')\n",
    "    def_reader = pd.read_csv(def_path[0], sep='\\\\s+', names=['1','2','3','4','5'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_reader[def_reader['4'].isin(['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_col_name = ['N','E','g','J','Unc'] + list(def_reader[def_reader['4'].isin(['label'])]['1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
